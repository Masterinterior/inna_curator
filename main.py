import os
import re
import time
import json
import base64
import asyncio
from typing import Dict, List, Any, Optional, Tuple

import requests
from fastapi import FastAPI, Request

# ================= ENV =================
TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

HTTP_TIMEOUT = 25
MAX_IMAGE_BYTES = 6_000_000

# Knowledge base file
KB_PATH = "knowledge/knowledge.txt"

# ================= APP =================
app = FastAPI()

# ================= MEMORY =================
CONTEXT_LIMIT = 14  # keep last 12-14 messages
CHAT_CONTEXT: Dict[int, List[Dict[str, Any]]] = {}

# recent assistant outputs (to reduce repetition)
RECENT_ASSISTANT: Dict[int, List[str]] = {}
RECENT_LIMIT = 6

# ======== IMAGE HISTORY ========
IMAGE_KEEP = 12  # store more now because albums
IMAGE_HISTORY: Dict[int, List[Dict[str, Any]]] = {}
IMAGE_SEQ: Dict[int, int] = {}  # photo counter: #1, #2, ...

# ======== ALBUM BUFFER (Variant 2) ========
ALBUM_DEBOUNCE_SEC = 2.0
ALBUM_BUFFER: Dict[Tuple[int, str], Dict[str, Any]] = {}  # (chat_id, album_id) -> data

# legacy last image store (optional)
LAST_IMAGE: Dict[int, bytes] = {}
LAST_IMAGE_AT: Dict[int, float] = {}
IMAGE_TTL = 60 * 30  # 30 minutes


def has_fresh_image(chat_id: int) -> bool:
    if chat_id not in LAST_IMAGE:
        return False
    return (time.time() - LAST_IMAGE_AT.get(chat_id, 0)) <= IMAGE_TTL


# ================= SYSTEM ROLE =================
SYSTEM_ROLE = (
    "–¢—ã ‚Äî –ò–Ω–Ω–∞, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω–µ—Ä –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞ –∏ –∫—É—Ä–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —à–∫–æ–ª—ã. "
    "–£ —Ç–µ–±—è –µ—Å—Ç—å –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–æ —É—Ä–æ–∫–∞–º –∏ —Ç—ã –≤—Å–µ–≥–¥–∞ –æ–ø–∏—Ä–∞–µ—à—å—Å—è –Ω–∞ –Ω–µ—ë, –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –æ–±—É—á–µ–Ω–∏–µ. "
    "–¢—ã —É–≤–µ—Ä–µ–Ω–Ω–∞—è, —ç–º–ø–∞—Ç–∏—á–Ω–∞—è –∂–µ–Ω—â–∏–Ω–∞. "
    "–¢—ã –≥–æ–≤–æ—Ä–∏—à—å —Å–ø–æ–∫–æ–π–Ω–æ, –ø–æ –¥–µ–ª—É, –±–µ–∑ –∑–∞—É–º–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ. "
    "–í–ê–ñ–ù–û: –ü–∏—à–∏ –±–µ–∑ Markdown (**–∑–≤—ë–∑–¥–æ—á–µ–∫**). –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –≤—ã–¥–µ–ª–µ–Ω–∏–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π HTML-—Ç–µ–≥–∏ <b> –∏ <i>. "
    "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å—ã–ª–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –≤–æ–ø—Ä–æ—Å–∞ ‚Äî "
    "—Ç—ã –¥–∞—ë—à—å –∫–æ—Ä–æ—Ç–∫–∏–π —Ç—ë–ø–ª—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (2‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), "
    "–æ—Ç–º–µ—á–∞–µ—à—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã "
    "–∏ –º—è–≥–∫–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å, —á–µ–º –º–æ–∂–µ—à—å –ø–æ–º–æ—á—å –¥–∞–ª—å—à–µ. "
    "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—á–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ. "
    "–ï—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—à—å –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ‚Äî –≤—Å–µ–≥–¥–∞ –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. "
    "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –æ–±—É—á–µ–Ω–∏–µ –∏ —É—Ä–æ–∫–∏ ‚Äî –ù–ï –ø–∏—à–∏ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã ¬´–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫—É—Ä—Å–∞¬ª –∏ —Ç.–ø., "
    "–∞ —Å—Ä–∞–∑—É –¥–∞–≤–∞–π —Ç–æ—á–Ω—ã–µ –º–µ—Å—Ç–∞ –∏–∑ –Ω–∞—à–µ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã. "
    "–ß–∞—Å—Ç–æ –∑–∞–∫–∞–Ω—á–∏–≤–∞–π –æ—Ç–≤–µ—Ç –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å: ¬´–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî –º–æ–≥—É‚Ä¶¬ª. "
    "–ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∂–∏ —É–º–µ—Å—Ç–Ω–æ."
)

# ================= TELEGRAM TEXT SANITIZE =================
MD_BOLD_RE = re.compile(r"\*\*(.+?)\*\*")
MD_ITALIC_RE = re.compile(r"(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)")


def to_tg_html(text: str) -> str:
    """
    Telegram uses parse_mode=HTML.
    Convert basic Markdown (**bold**, *italic*) to HTML to avoid showing stars.
    Keeps existing HTML tags (KB already uses <b>).
    """
    t = (text or "").strip()
    if not t:
        return t
    t = MD_BOLD_RE.sub(r"<b>\1</b>", t)
    t = MD_ITALIC_RE.sub(r"<i>\1</i>", t)
    t = t.replace("**", "")
    return t


# ================= TELEGRAM =================
def tg_send(chat_id: int, text: str):
    try:
        safe = to_tg_html(text)
        r = requests.post(
            f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage",
            json={
                "chat_id": chat_id,
                "text": safe,
                "parse_mode": "HTML",
                "disable_web_page_preview": True,
            },
            timeout=HTTP_TIMEOUT,
        )
        if r.status_code != 200:
            print("TG sendMessage error:", r.status_code, r.text)
    except Exception as e:
        print("TG sendMessage exception:", repr(e))


def tg_typing(chat_id: int):
    try:
        requests.post(
            f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendChatAction",
            json={"chat_id": chat_id, "action": "typing"},
            timeout=HTTP_TIMEOUT,
        )
    except Exception as e:
        print("TG typing exception:", repr(e))


def tg_get_photo(file_id: str) -> Optional[bytes]:
    try:
        meta = requests.get(
            f"https://api.telegram.org/bot{TG_BOT_TOKEN}/getFile",
            params={"file_id": file_id},
            timeout=HTTP_TIMEOUT,
        ).json()

        if not meta.get("ok"):
            return None

        path = meta["result"]["file_path"]
        img = requests.get(
            f"https://api.telegram.org/file/bot{TG_BOT_TOKEN}/{path}",
            timeout=HTTP_TIMEOUT,
        ).content

        if img and len(img) <= MAX_IMAGE_BYTES:
            return img
        return None
    except Exception as e:
        print("TG getPhoto exception:", repr(e))
        return None


# ================= OPENAI =================
def openai_chat(messages: List[Dict[str, Any]], max_tokens: int = 900, temperature: float = 0.45) -> str:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)

        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return (r.choices[0].message.content or "").strip()
    except Exception as e:
        print("OPENAI chat exception:", repr(e))
        return "–°–µ–π—á–∞—Å —É –º–µ–Ω—è –Ω–µ–±–æ–ª—å—à–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–∞—É–∑–∞ üôè –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."


def openai_with_image(
    prompt: str,
    image: bytes,
    context: List[Dict[str, Any]],
    max_tokens: int = 900,
    temperature: float = 0.55,
) -> str:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)

        b64 = base64.b64encode(image).decode()

        messages = (
            [{"role": "system", "content": SYSTEM_ROLE}]
            + context
            + [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}},
                ],
            }]
        )

        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return (r.choices[0].message.content or "").strip()
    except Exception as e:
        print("OPENAI image exception:", repr(e))
        return "–Ø –≤–∏–∂—É, —á—Ç–æ –ø—Ä–∏—à–ª–æ —Ñ–æ—Ç–æ, –Ω–æ —Å–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –µ–≥–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –∏–∑-–∑–∞ —Ç–µ—Ö. –ø–∞—É–∑—ã üôè –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑."


# ================= CONTEXT =================
def add_context(chat_id: int, role: str, content: str):
    CHAT_CONTEXT.setdefault(chat_id, [])
    CHAT_CONTEXT[chat_id].append({"role": role, "content": content})
    CHAT_CONTEXT[chat_id] = CHAT_CONTEXT[chat_id][-CONTEXT_LIMIT:]


def remember_assistant(chat_id: int, text: str):
    RECENT_ASSISTANT.setdefault(chat_id, [])
    RECENT_ASSISTANT[chat_id].append((text or "")[:900])
    RECENT_ASSISTANT[chat_id] = RECENT_ASSISTANT[chat_id][-RECENT_LIMIT:]


def avoid_repetition_hint(chat_id: int) -> str:
    recent = RECENT_ASSISTANT.get(chat_id) or []
    if not recent:
        return ""
    last = "\n---\n".join(recent[-3:])
    return (
        "–í–ê–ñ–ù–û: –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –¥–æ—Å–ª–æ–≤–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã –∏ –∏–∑–±–µ–≥–∞–π —à—Ç–∞–º–ø–æ–≤ "
        "(¬´—É—é—Ç–Ω–æ –∏ —Å—Ç–∏–ª—å–Ω–æ¬ª, ¬´—Ç–µ–ø–ª–∞—è –ø–∞–ª–∏—Ç—Ä–∞¬ª, ¬´–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ—Å—Ç—å¬ª, ¬´–µ—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî –º–æ–≥—É‚Ä¶¬ª). "
        "–ú–µ–Ω—è–π –ª–µ–∫—Å–∏–∫—É –∏ —Ñ–æ–∫—É—Å: –∫–æ–º–ø–æ–∑–∏—Ü–∏—è/—Å–≤–µ—Ç/—Ü–≤–µ—Ç/—Ñ—É–Ω–∫—Ü–∏—è/–º–∞—Ç–µ—Ä–∏–∞–ª—ã.\n"
        f"–ù–ï –ü–û–í–¢–û–†–Ø–ô —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤:\n{last}"
    )


# ======== IMAGE HISTORY HELPERS ========
IMAGE_REF_RE = re.compile(
    r"(–Ω–∞\s+—Ñ–æ—Ç–æ|–Ω–∞\s+–∫–∞—Ä—Ç–∏–Ω–∫–µ|–ø–æ\s+—Ñ–æ—Ç–æ|–ø–æ\s+–∫–∞—Ä—Ç–∏–Ω–∫–µ|–ø–æ—Å–º–æ—Ç—Ä–∏|–æ—Ü–µ–Ω(–∏|–∫–∞)|"
    r"—á—Ç–æ\s+–Ω–µ\s+—Ç–∞–∫|—á—Ç–æ\s+–∏—Å–ø—Ä–∞–≤–∏—Ç—å|–ø–µ—Ä–µ–¥–µ–ª–∞–π|–≤–∞—Ä–∏–∞–Ω—Ç|–ø–ª–∞–Ω–∏—Ä–æ–≤–∫|"
    r"–≤\s+—ç—Ç–æ–º\s+–∏–Ω—Ç–µ—Ä—å–µ—Ä–µ|–∑–¥–µ—Å—å|—Ç—É—Ç|—ç—Ç–æ\s+—Ñ–æ—Ç–æ|—ç—Ç–æ\s+–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ|"
    r"–ø—Ä–µ–¥—ã–¥—É—â(–µ–µ|–µ–º)\s+—Ñ–æ—Ç–æ|–ø—Ä–æ—à–ª(–æ–µ|–æ–º)\s+—Ñ–æ—Ç–æ|–ø–µ—Ä–≤(–æ–µ|–æ–º)\s+—Ñ–æ—Ç–æ|–≤—Ç–æ—Ä(–æ–µ|–æ–º)\s+—Ñ–æ—Ç–æ|—Ç—Ä–µ—Ç—å(–µ|–µ–º)\s+—Ñ–æ—Ç–æ)",
    re.IGNORECASE,
)
ORDINAL_RE = re.compile(r"\b(–ø–µ—Ä–≤|–≤—Ç–æ—Ä|—Ç—Ä–µ—Ç|—á–µ—Ç–≤–µ—Ä|–ø—è—Ç)\w*\b", re.IGNORECASE)

VISUAL_TOPIC_RE = re.compile(
    r"(–∏–Ω—Ç–µ—Ä—å–µ—Ä|–∫–æ–º–Ω–∞—Ç|–ø–æ–º–µ—â–µ–Ω|–ø–ª–∞–Ω–∏—Ä–æ–≤–∫|—Å—Ç–∏–ª|—Ü–≤–µ—Ç|–ø–∞–ª–∏—Ç—Ä|—Å–≤–µ—Ç|–æ—Å–≤–µ—â–µ–Ω|"
    r"–¥–∏–≤–∞–Ω|–∫—Ä–µ—Å–ª|–∫—É—Ö–Ω|–≤–∞–Ω–Ω|—Å–∞–Ω—É–∑|—Å–ø–∞–ª—å–Ω|–≥–æ—Å—Ç–∏–Ω|–¥–µ—Ç—Å–∫|–ø—Ä–∏—Ö–æ–∂|"
    r"—Å–ª–∏—à–∫–æ–º|–º—É–∂—Å–∫|–∂–µ–Ω—Å–∫|–¥–µ–≤—á–∞—á|—É—é—Ç–Ω|—Ö–æ–ª–æ–¥–Ω|—Ç–µ–ø–ª|–¥–µ—à–µ–≤|–¥–æ—Ä–æ–≥|"
    r"—á—Ç–æ\s+–¥–æ–±–∞–≤–∏—Ç—å|—á—Ç–æ\s+—É–±—Ä–∞—Ç—å|–∫–∞–∫\s+—É–ª—É—á—à–∏—Ç—å|–∫–∞–∫\s+–∏—Å–ø—Ä–∞–≤–∏—Ç—å)",
    re.IGNORECASE,
)

COMPARE_RE = re.compile(
    r"(–∫–∞–∫–æ–π\s+–≤–∞—Ä–∏–∞–Ω—Ç|—á—Ç–æ\s+–ª—É—á—à–µ|—Å—Ä–∞–≤–Ω–∏|–ª–µ–≤—ã–π|–ø—Ä–∞–≤—ã–π|1\s+–∏–ª–∏\s+2|–ø–µ—Ä–≤—ã–π\s+–∏–ª–∏\s+–≤—Ç–æ—Ä–æ–π|–≤—ã–±–µ—Ä–∏\s+–ª—É—á—à–∏–π|–∫–∞–∫–æ–π\s+–Ω—Ä–∞–≤–∏—Ç—Å—è)",
    re.IGNORECASE,
)
PHOTO_NUM_RE = re.compile(r"#\s*(\d+)")


def push_image(chat_id: int, img: bytes, desc: str, album_id: Optional[str] = None) -> int:
    IMAGE_SEQ[chat_id] = IMAGE_SEQ.get(chat_id, 0) + 1
    num = IMAGE_SEQ[chat_id]

    IMAGE_HISTORY.setdefault(chat_id, [])
    IMAGE_HISTORY[chat_id].append({
        "num": num,
        "ts": time.time(),
        "image": img,
        "desc": (desc or "").strip(),
        "album_id": album_id,
    })
    IMAGE_HISTORY[chat_id] = IMAGE_HISTORY[chat_id][-IMAGE_KEEP:]
    return num


def pick_image_from_history(chat_id: int, user_text: str) -> Optional[Dict[str, Any]]:
    hist = IMAGE_HISTORY.get(chat_id) or []
    if not hist:
        return None
    t = (user_text or "").lower()

    if "–ø—Ä–µ–¥—ã–¥—É—â" in t or "–ø—Ä–æ—à–ª" in t:
        return hist[-2] if len(hist) >= 2 else hist[-1]

    nums = [int(x) for x in PHOTO_NUM_RE.findall(user_text)]
    if nums:
        target = nums[0]
        for it in hist:
            if it.get("num") == target:
                return it

    if ORDINAL_RE.search(t):
        if "–ø–µ—Ä–≤" in t:
            target = 1
        elif "–≤—Ç–æ—Ä" in t:
            target = 2
        elif "—Ç—Ä–µ—Ç" in t:
            target = 3
        elif "—á–µ—Ç–≤–µ—Ä" in t:
            target = 4
        elif "–ø—è—Ç" in t:
            target = 5
        else:
            target = None
        if target is not None:
            for it in hist:
                if it.get("num") == target:
                    return it
            return hist[-1]

    return hist[-1]


def build_visual_context_messages(chat_id: int, limit: int = 4) -> List[Dict[str, Any]]:
    hist = IMAGE_HISTORY.get(chat_id) or []
    if not hist:
        return []
    tail = hist[-limit:]
    parts = []
    for it in tail:
        num = it.get("num", "?")
        desc = (it.get("desc") or "").strip()
        if desc:
            parts.append(f"–§–æ—Ç–æ #{num}: {desc}")
    if not parts:
        return []
    joined = "\n\n".join(parts).strip()
    return [{"role": "assistant", "content": f"–í–∏–∑—É–∞–ª—å–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º —Ñ–æ—Ç–æ:\n{joined}"}]


def get_context(chat_id: int) -> List[Dict[str, Any]]:
    ctx = CHAT_CONTEXT.get(chat_id, []).copy()
    return build_visual_context_messages(chat_id, limit=4) + ctx


# ================= INTENT: KB LINKS VS HOW-TO =================
COURSE_LOCATOR_RE = re.compile(
    r"(–≤\s+–∫–∞–∫–æ–º\s+—É—Ä–æ–∫–µ|–∫–∞–∫–æ–π\s+—É—Ä–æ–∫|–≥–¥–µ\s+–≤\s+–∫—É—Ä—Å–µ|–≥–¥–µ\s+—ç—Ç–æ\s+–≤\s+–æ–±—É—á–µ–Ω–∏–∏|"
    r"–¥–∞–π\s+—Å—Å—ã–ª–∫|—Å–∫–∏–Ω—å\s+—Å—Å—ã–ª–∫|—Å—Å—ã–ª–∫–∞\s+–Ω–∞\s+—É—Ä–æ–∫|–≥–¥–µ\s+–ø–æ—Å–º–æ—Ç—Ä–µ—Ç|"
    r"–≤\s+–∫–∞–∫–æ–º\s+–º–æ–¥—É–ª|–≤\s+–∫–∞–∫–æ–π\s+—Å—Ç—É–ø–µ–Ω|–ª–µ–∂–∏—Ç\s+–≤\s+–ø—Ä–æ–≥—Ä–∞–º–º–µ)",
    re.IGNORECASE,
)

HOWTO_RE = re.compile(
    r"(–∫–∞–∫\s+—Å–¥–µ–ª–∞—Ç—å|–∫–∞–∫\s+—Å–æ–±—Ä–∞—Ç—å|–∫–∞–∫\s+—Å–æ–∑–¥–∞—Ç—å|–∫–∞–∫\s+–Ω–∞—Å—Ç—Ä–æ–∏—Ç—å|"
    r"–æ–±—ä—è—Å–Ω–∏|–ø–æ–∫–∞–∂–∏|–∏–Ω—Å—Ç—Ä—É–∫—Ü|–ø–æ—à–∞–≥–æ–≤–æ|–º–Ω–µ\s+–Ω—É–∂–Ω–æ|—Ö–æ—á—É\s+—Å–¥–µ–ª–∞—Ç—å|"
    r"–Ω–µ\s+–ø–æ–Ω—è–ª|–Ω–µ\s+–ø–æ–Ω—è–ª–∞|–Ω–µ\s+–ø–æ–ª—É—á–∞–µ—Ç—Å—è|–æ—à–∏–±–∫–∞|–ø–æ—á–µ–º—É)",
    re.IGNORECASE,
)


def should_show_kb_links(text: str) -> bool:
    return bool(text and COURSE_LOCATOR_RE.search(text))


def is_howto(text: str) -> bool:
    return bool(text and HOWTO_RE.search(text))


# ================= KB (semantic retrieval + LLM rerank) =================
KB_INDEX: List[Dict[str, Any]] = []

COURSE_RE = re.compile(r"^\s*–°–¢–†–£–ö–¢–£–†–ê\s+–ö–£–†–°–ê", re.IGNORECASE)
STEP_RE = re.compile(r"^\s*\d+\s*—Å—Ç—É–ø–µ–Ω", re.IGNORECASE)
MODULE_RE = re.compile(r"^\s*\d+\s*–º–æ–¥—É–ª", re.IGNORECASE)
LESSON_RE = re.compile(r"^\s*\d+\s*—É—Ä–æ–∫\b", re.IGNORECASE)

URL_LINE_RE = re.compile(r"(https?://\S+)", re.IGNORECASE)
LESSON_URL_LINE_RE = re.compile(r"(?:–°—Å—ã–ª–∫–∞\s+–Ω–∞\s+—É—Ä–æ–∫|–°—Å—ã–ª–∫–∞)\s*:\s*(https?://\S+)", re.IGNORECASE)
DZ_RE = re.compile(r"^\s*–î–ó(?:\s*\([^)]+\))?\s*:\s*(.+)$", re.IGNORECASE)

SECTION_FULL_RE = re.compile(
    r"^–†–∞–∑–¥–µ–ª\s*[¬´\"\']?([^¬ª\"\'\:]+)[¬ª\"\']?\s*:\s*(.+)$",
    re.IGNORECASE
)


def normalize(s: str) -> str:
    s = (s or "").lower().strip().replace("—ë", "–µ")
    s = re.sub(r"[\"'‚Äú‚Äù¬´¬ª]", "", s)
    s = re.sub(r"\s+", " ", s)
    return s


def split_materials(s: str) -> List[str]:
    parts = [p.strip() for p in (s or "").split(",")]
    parts = [p.strip(" .;") for p in parts if p.strip()]
    return parts


def load_kb() -> Tuple[int, str]:
    global KB_INDEX
    if not os.path.exists(KB_PATH):
        KB_INDEX = []
        return 0, f"KB not found: {KB_PATH}"

    lines = [ln.rstrip() for ln in open(KB_PATH, "r", encoding="utf-8", errors="ignore").read().splitlines()]
    if not lines:
        KB_INDEX = []
        return 0, "KB empty"

    course_title, course_url = "", ""
    step_title, step_url = "", ""
    module_title, module_url = "", ""

    KB_INDEX = []
    i = 0
    while i < len(lines):
        ln = (lines[i] or "").strip()
        if not ln:
            i += 1
            continue

        if COURSE_RE.search(ln):
            course_title = ln
            course_url = ""
            j = i + 1
            while j < len(lines) and not lines[j].strip():
                j += 1
            if j < len(lines):
                m = URL_LINE_RE.search(lines[j].strip())
                if m:
                    course_url = m.group(1).rstrip(").,;")
                    i = j
            i += 1
            continue

        if STEP_RE.search(ln):
            step_title = ln
            step_url = ""
            j = i + 1
            while j < len(lines) and not lines[j].strip():
                j += 1
            if j < len(lines):
                m = URL_LINE_RE.search(lines[j].strip())
                if m:
                    step_url = m.group(1).rstrip(").,;")
                    i = j
            module_title, module_url = "", ""
            i += 1
            continue

        if MODULE_RE.search(ln):
            module_title = ln
            module_url = ""
            j = i + 1
            while j < len(lines) and not lines[j].strip():
                j += 1
            if j < len(lines):
                m = URL_LINE_RE.search(lines[j].strip())
                if m:
                    module_url = m.group(1).rstrip(").,;")
                    i = j
            i += 1
            continue

        if LESSON_RE.search(ln):
            lesson_title = ln
            lesson_url = ""
            sections: List[str] = []
            homework = ""

            j = i + 1
            while j < len(lines):
                cur = (lines[j] or "").strip()
                if not cur:
                    j += 1
                    continue
                if COURSE_RE.search(cur) or STEP_RE.search(cur) or MODULE_RE.search(cur) or LESSON_RE.search(cur):
                    break

                mlu = LESSON_URL_LINE_RE.search(cur)
                if mlu:
                    lesson_url = mlu.group(1).rstrip(").,;")
                else:
                    mdz = DZ_RE.search(cur)
                    if mdz:
                        homework = mdz.group(1).strip()
                    else:
                        sections.append(cur)

                j += 1

            lesson_blob = "\n".join(sections).strip()

            section_items: List[Tuple[str, List[str]]] = []
            for s in sections:
                msec = SECTION_FULL_RE.match(s.strip())
                if not msec:
                    continue
                sec_title = msec.group(1).strip()
                materials_raw = msec.group(2).strip()
                mats = split_materials(materials_raw) if materials_raw else []
                section_items.append((sec_title, mats))

            if not section_items:
                section_items = [("", ["(–º–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ —É–∫–∞–∑–∞–Ω)"])]

            for sec_title, mats in section_items:
                if not mats:
                    mats = ["(–º–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ —É–∫–∞–∑–∞–Ω)"]

                for mat in mats:
                    KB_INDEX.append({
                        "type": "micro",
                        "kind": "–í–∏–¥–µ–æ—É—Ä–æ–∫",
                        "course_title": course_title,
                        "course_url": course_url,
                        "step_title": step_title,
                        "step_url": step_url,
                        "module_title": module_title,
                        "module_url": module_url,
                        "lesson_title": lesson_title,
                        "lesson_url": lesson_url,
                        "section_title": sec_title,
                        "material_title": mat,
                        "homework": homework,
                        "lesson_blob": lesson_blob,
                        "text": normalize(" ".join([
                            course_title, step_title, module_title, lesson_title,
                            sec_title, mat, lesson_blob, homework
                        ])),
                    })

            i = j
            continue

        i += 1

    return len(KB_INDEX), "OK"


def kb_candidates(query: str, k: int = 20) -> List[Dict[str, Any]]:
    if not query or not KB_INDEX:
        return []

    q = normalize(query)

    expansions: List[str] = []
    if "–≤–∞–Ω–Ω" in q:
        expansions += ["—Å–∞–Ω—É–∑–µ–ª", "—Å–∞–Ω—É–∑–ª—ã", "—Ç—É–∞–ª–µ—Ç"]
    if "—Å–∞–Ω—É–∑" in q or "—Ç—É–∞–ª–µ—Ç" in q:
        expansions += ["–≤–∞–Ω–Ω–∞—è", "–≤–∞–Ω–Ω–∞"]

    if "3d" in q or "3–¥" in q:
        expansions += ["3–¥", "3d", "–∫–æ–ª–ª–∞–∂", "3–¥ –∫–æ–ª–ª–∞–∂", "3d –∫–æ–ª–ª–∞–∂", "3–¥ –∫–æ–ª–ª–∞–∂–∞"]
    if "–∫–æ–ª–ª–∞–∂" in q:
        expansions += ["3–¥", "3d", "3–¥ –∫–æ–ª–ª–∞–∂–∞", "3d –∫–æ–ª–ª–∞–∂–∞", "–º—É–¥–±–æ—Ä–¥", "–∫–æ–Ω—Ü–µ–ø—Ç-–∫–æ–ª–ª–∞–∂"]

    if "photoshop" in q or "—Ñ–æ—Ç–æ—à–æ–ø" in q:
        expansions += ["ps", "adobe photoshop"]

    terms = [w for w in re.findall(r"[a-z–∞-—è0-9]+", q) if len(w) >= 3]
    for e in expansions:
        terms += [w for w in re.findall(r"[a-z–∞-—è0-9]+", normalize(e)) if len(w) >= 3]
    terms = list(dict.fromkeys(terms))

    need_bath = ("–≤–∞–Ω–Ω" in q) or ("—Å–∞–Ω—É–∑" in q) or ("—Ç—É–∞–ª–µ—Ç" in q)
    bath_terms = ["—Å–∞–Ω—É–∑", "–≤–∞–Ω–Ω", "—Ç—É–∞–ª–µ—Ç"]

    scored: List[Tuple[float, Dict[str, Any]]] = []
    for it in KB_INDEX:
        t = it.get("text", "")
        if not t:
            continue

        score = 0.0
        mt = normalize(it.get("material_title", ""))
        lb = normalize(it.get("lesson_blob", ""))
        hw = normalize(it.get("homework", ""))

        for w in terms:
            if w in t:
                score += 1.0
            if w in mt:
                score += 1.5
            if w in lb:
                score += 1.2
            if w in hw:
                score += 2.6

        if need_bath and any(bt in t for bt in bath_terms):
            score += 3.0

        if score > 0:
            scored.append((score, it))

    scored.sort(key=lambda x: x[0], reverse=True)

    uniq: List[Dict[str, Any]] = []
    seen = set()
    for _, it in scored:
        key = (it.get("lesson_url"), it.get("section_title"), it.get("material_title"))
        if key in seen:
            continue
        seen.add(key)
        uniq.append(it)
        if len(uniq) >= k:
            break

    return uniq


def kb_select_with_llm(user_query: str, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not candidates:
        return []

    packed = []
    for idx, it in enumerate(candidates[:20], 1):
        packed.append({
            "id": idx,
            "step": it.get("step_title", ""),
            "module": it.get("module_title", ""),
            "lesson": it.get("lesson_title", ""),
            "section": it.get("section_title", ""),
            "material": it.get("material_title", ""),
            "url": it.get("lesson_url", ""),
            "homework": it.get("homework", ""),
            "blob": (it.get("lesson_blob", "")[:550] if it.get("lesson_blob") else ""),
        })

    selector_system = (
        "–¢—ã ‚Äî –º–µ—Ç–æ–¥–∏—Å—Ç –∏ –∫—É—Ä–∞—Ç–æ—Ä –∫—É—Ä—Å–∞ –¥–∏–∑–∞–π–Ω–∞ –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞.\n"
        "–¢–µ–±–µ –¥–∞–ª–∏ –≤–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.\n"
        "–ó–∞–¥–∞—á–∞: –≤—ã–±—Ä–∞—Ç—å –¥–æ 3 —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ü–û –°–ú–´–°–õ–£.\n"
        "–£—á–∏—Ç—ã–≤–∞–π —Å–∏–Ω–æ–Ω–∏–º—ã (–≤–∞–Ω–Ω–∞—è=—Å–∞–Ω—É–∑–µ–ª), —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –≤ –î–ó, —Ü–µ–ª—å —É—Ä–æ–∫–∞, –∏ —Ä–∞–∑–¥–µ–ª—ã.\n"
        "–ï—Å–ª–∏ –≤ –±–∞–∑–µ –ù–ï–¢ –Ω–∏—á–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ ‚Äî –≤–µ—Ä–Ω–∏ NONE.\n"
        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –≤–æ–∫—Ä—É–≥:\n"
        "{\"pick\":[1,5],\"reason\":\"...\"} –∏–ª–∏ {\"pick\":[],\"reason\":\"NONE\"}\n"
    )

    raw = openai_chat(
        [
            {"role": "system", "content": selector_system},
            {"role": "user", "content": f"–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞:\n{user_query}\n\n–ö–∞–Ω–¥–∏–¥–∞—Ç—ã:\n{json.dumps(packed, ensure_ascii=False)}"},
        ],
        max_tokens=350,
        temperature=0.25,
    )

    try:
        data = json.loads(raw)
        picks = data.get("pick", [])
        if not picks:
            return []
        chosen = []
        for p in picks[:3]:
            if isinstance(p, int) and 1 <= p <= len(candidates[:20]):
                chosen.append(candidates[p - 1])
        return chosen
    except Exception:
        return candidates[:1]


def best_material_name(it: Dict[str, Any], user_query: str) -> str:
    q = normalize(user_query)
    hw = (it.get("homework") or "").strip()
    mat = (it.get("material_title") or "").strip()

    if ("–∫–æ–ª–ª–∞–∂" in q or "3–¥" in q or "3d" in q) and hw:
        return hw if len(hw) <= 240 else (hw[:240].rstrip() + "‚Ä¶")

    return mat or "(–º–∞—Ç–µ—Ä–∏–∞–ª)"


def dedupe_hits_by_lesson(hits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not hits:
        return []
    out: List[Dict[str, Any]] = []
    seen = set()
    for it in hits:
        key = (it.get("lesson_url") or "").strip() or (it.get("lesson_title") or "").strip()
        if not key:
            continue
        if key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out


def format_kb_hits(hits: List[Dict[str, Any]], user_query: str) -> str:
    if not hits:
        return ""

    hits = dedupe_hits_by_lesson(hits)

    out = ["\n\nüìö <b>–ù–∞—à–ª–∞ –≤ –æ–±—É—á–µ–Ω–∏–∏:</b>"]
    for it in hits[:3]:
        out.append("\nüìå <b>–ú–∞—Ç–µ—Ä–∏–∞–ª:</b> –í–∏–¥–µ–æ—É—Ä–æ–∫")

        out.append("\n<b>–ì–¥–µ –ª–µ–∂–∏—Ç –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ:</b>")
        if it.get("step_title"):
            out.append(f"‚Äî <b>–°—Ç—É–ø–µ–Ω—å:</b> {it.get('step_title')}")
        if it.get("module_title"):
            out.append(f"‚Äî <b>–ú–æ–¥—É–ª—å:</b> {it.get('module_title')}")
        if it.get("lesson_title"):
            out.append(f"‚Äî <b>–£—Ä–æ–∫:</b> {it.get('lesson_title')}")
        if it.get("section_title"):
            out.append(f"‚Äî <b>–†–∞–∑–¥–µ–ª:</b> {it.get('section_title')}")

        out.append(f"\n<b>–ù–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞:</b> {best_material_name(it, user_query)}")

        url = it.get("lesson_url", "")
        if url:
            out.append(f"\n<b>–°—Å—ã–ª–∫–∞:</b>\n{url}")

        hw = (it.get("homework") or "").strip()
        if hw:
            out.append("\n<b>–î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ:</b>")
            out.append(f"{hw}")

    return "\n".join(out).strip()


@app.on_event("startup")
def _startup():
    n, msg = load_kb()
    print(f"KB loaded: {n} items, status: {msg}")
def should_show_kb_links(text: str) -> bool:
    if not text:
        return False

    t = normalize(text)

    # 1) –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–æ "—É—Ä–æ–∫" ‚Äî —ç—Ç–æ –µ—â—ë –Ω–µ —Ç–æ—á–Ω–æ.
    # –°—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ "—É—Ä–æ–∫" + –º–∞—Ä–∫–µ—Ä –ø–æ–∏—Å–∫–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ.
    has_lesson_word = ("—É—Ä–æ–∫" in t)

    has_locator_words = any(w in t for w in [
        "–≥–¥–µ", "–≤ –∫–∞–∫–æ–º", "–∫–∞–∫–æ–π", "–ª–µ–∂–∏—Ç", "–Ω–∞–π—Ç–∏", "–æ—Ç–∫—Ä—ã—Ç—å", "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å",
        "–≤ –∫—É—Ä—Å–µ", "–≤ –æ–±—É—á–µ–Ω–∏–∏", "–≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ", "–≤ –º–æ–¥—É–ª–µ", "–≤ —Å—Ç—É–ø–µ–Ω–∏",
        "–º–æ–¥—É–ª—å", "—Å—Ç—É–ø–µ–Ω—å", "—Ä–∞–∑–¥–µ–ª"
    ])

    if has_lesson_word and has_locator_words:
        return True

    # 2) –ò–ª–∏ —Å—Ç—Ä–æ–≥–∏–µ —Ñ—Ä–∞–∑—ã –±–µ–∑ —Å–ª–æ–≤–∞ "—É—Ä–æ–∫"
    # (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–≤ –∫–∞–∫–æ–º –º–æ–¥—É–ª–µ —ç—Ç–æ?" ‚Äî —Ç–æ–∂–µ –ø—Ä–æ –ø—Ä–æ–≥—Ä–∞–º–º—É)
    return bool(COURSE_LOCATOR_RE.search(text))

# ================= ALBUM PROCESSOR =================
async def _process_album(chat_id: int, album_id: str):
    key = (chat_id, album_id)
    data = ALBUM_BUFFER.get(key)
    if not data:
        return

    # wait debounce to collect last images
    await asyncio.sleep(ALBUM_DEBOUNCE_SEC)

    # if updated after scheduling, rescheduled task will handle it
    data2 = ALBUM_BUFFER.get(key)
    if not data2 or data2.get("task_id") != data.get("task_id"):
        return

    images: List[bytes] = data2.get("images", [])
    caption: str = (data2.get("caption") or "").strip()

    # remove from buffer now
    ALBUM_BUFFER.pop(key, None)

    if not images:
        return

    tg_typing(chat_id)

    # describe each image, store in history
    nums: List[int] = []
    descs: List[Tuple[int, str]] = []
    for idx, img in enumerate(images, 1):
        describe_prompt = (
            "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, —á—Ç–æ–±—ã —è –º–æ–≥–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö. "
            "–ï—Å–ª–∏ —ç—Ç–æ –∏–Ω—Ç–µ—Ä—å–µ—Ä ‚Äî —É–∫–∞–∂–∏ —Ç–∏–ø –ø–æ–º–µ—â–µ–Ω–∏—è, –ø–ª–∞–Ω, –º–µ–±–µ–ª—å, —Ü–≤–µ—Ç–∞, —Å–≤–µ—Ç, —Å—Ç–∏–ª—å. "
            "–ï—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–µ–¥–º–µ—Ç ‚Äî —É–∫–∞–∂–∏ –º–∞—Ç–µ—Ä–∏–∞–ª, —Ü–≤–µ—Ç, —Ñ–æ—Ä–º—É, —Å—Ç–∏–ª—å, —Ñ–∞–∫—Ç—É—Ä—É. "
            "–°–¥–µ–ª–∞–π 5‚Äì7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –±–µ–∑ –≤–æ–¥—ã."
        )
        desc = openai_with_image(describe_prompt, img, [], max_tokens=320, temperature=0.35)
        num = push_image(chat_id, img, desc, album_id=album_id)
        nums.append(num)
        descs.append((num, desc))

    # Add a single "album marker" to chat context (helps references later)
    add_context(chat_id, "user", f"[–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª –∞–ª—å–±–æ–º —Ñ–æ—Ç–æ: {', '.join([f'#{n}' for n in nums])}]")

    # If caption exists -> answer based on caption + ALL descriptions (chat-style)
    if caption:
        add_context(chat_id, "user", caption)

        # If caption implies comparison, compare all photos via descriptions
        if COMPARE_RE.search(caption) and len(descs) >= 2:
            packed = "\n\n".join([f"–§–æ—Ç–æ #{n}:\n{d}" for n, d in descs])
            messages = [
                {"role": "system", "content": SYSTEM_ROLE + "\n" + avoid_repetition_hint(chat_id)},
                {
                    "role": "user",
                    "content": (
                        f"{caption}\n\n"
                        "–ù–∏–∂–µ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (—ç—Ç–æ –æ–¥–∏–Ω –∞–ª—å–±–æ–º). "
                        "–í—ã–±–µ—Ä–∏ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –∏ –æ–±—ä—è—Å–Ω–∏:\n"
                        "1) –ü–æ–±–µ–¥–∏—Ç–µ–ª—å: —Ñ–æ—Ç–æ #...\n"
                        "2) 3 –ø—Ä–∏—á–∏–Ω—ã\n"
                        "3) –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–∏–≥—Ä–∞–≤—à–µ–≥–æ ‚Äî –ø–æ 1 —Ç–æ—á–µ—á–Ω–æ–π –ø—Ä–∞–≤–∫–µ (–∫–æ—Ä–æ—Ç–∫–æ)\n"
                        "–ë–µ–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑.\n\n"
                        f"{packed}"
                    ),
                },
            ]
            answer = openai_chat(messages, max_tokens=650, temperature=0.55)
            remember_assistant(chat_id, answer)
            add_context(chat_id, "assistant", answer)
            tg_send(chat_id, answer)
            return

        # Not comparison: answer caption like ChatGPT using the descriptions as context
        packed = "\n\n".join([f"–§–æ—Ç–æ #{n}:\n{d}" for n, d in descs])
        messages = [
            {"role": "system", "content": SYSTEM_ROLE + "\n" + avoid_repetition_hint(chat_id)},
            {
                "role": "user",
                "content": (
                    f"{caption}\n\n"
                    "–£ —Ç–µ–±—è –µ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è –≤—Å–µ—Ö —Ñ–æ—Ç–æ –∏–∑ –∞–ª—å–±–æ–º–∞ –Ω–∏–∂–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –∫–∞–∫ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. "
                    "–û—Ç–≤–µ—á–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É, –±–µ–∑ —Ñ—Ä–∞–∑—ã ¬´—è –Ω–µ –≤–∏–∂—É —Ñ–æ—Ç–æ¬ª. "
                    "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –≤—ã–±–æ—Ä ‚Äî –≤—ã–±–µ—Ä–∏ –∏ –æ–±–æ—Å–Ω—É–π.\n\n"
                    f"{packed}"
                ),
            },
        ]
        answer = openai_chat(messages, max_tokens=750, temperature=0.5)
        remember_assistant(chat_id, answer)
        add_context(chat_id, "assistant", answer)
        tg_send(chat_id, answer)
        return

    # No caption: one combined warm comment about album (varied focus)
    # rotate focus by album size/last num
    focus = ["–∫–æ–º–ø–æ–∑–∏—Ü–∏—é", "—Å–≤–µ—Ç", "—Ü–≤–µ—Ç", "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å", "–º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ —Ñ–∞–∫—Ç—É—Ä—ã"]
    f = focus[nums[-1] % len(focus)]
    packed_short = "\n\n".join([f"–§–æ—Ç–æ #{n}: {d[:220].strip()}‚Ä¶" for n, d in descs])
    messages = [
        {"role": "system", "content": SYSTEM_ROLE + "\n" + avoid_repetition_hint(chat_id)},
        {
            "role": "user",
            "content": (
                f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª –∞–ª—å–±–æ–º –∏–∑ {len(descs)} —Ñ–æ—Ç–æ –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏.\n"
                f"–î–∞–π –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (3‚Äì5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ {f}. "
                "–ó–∞—Ç–µ–º –∑–∞–¥–∞–π –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —á–µ–ª–æ–≤–µ–∫—É –Ω—É–∂–Ω–æ: –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç, –Ω–∞–π—Ç–∏ –æ—à–∏–±–∫–∏, "
                "–∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–∞–≤–∫–∏. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —à—Ç–∞–º–ø—ã.\n\n"
                f"–û–ø–∏—Å–∞–Ω–∏—è —Ñ–æ—Ç–æ:\n{packed_short}"
            ),
        },
    ]
    answer = openai_chat(messages, max_tokens=320, temperature=0.6)
    remember_assistant(chat_id, answer)
    add_context(chat_id, "assistant", answer)
    tg_send(chat_id, answer)


def _schedule_album(chat_id: int, album_id: str):
    key = (chat_id, album_id)
    data = ALBUM_BUFFER.get(key)
    if not data:
        return
    # bump task id so older tasks self-cancel
    data["task_id"] = str(time.time())
    ALBUM_BUFFER[key] = data
    asyncio.create_task(_process_album(chat_id, album_id))


# ================= WEBHOOK =================
@app.post("/webhook")
async def webhook(req: Request):
    update = await req.json()
    msg = update.get("message")
    if not msg:
        return {"ok": True}

    chat_id = msg["chat"]["id"]
    text = (msg.get("text") or "").strip()
    caption = (msg.get("caption") or "").strip()
    photos = msg.get("photo") or []
    album_id = msg.get("media_group_id")

    # ===== PHOTO RECEIVED =====
    if photos:
        img = tg_get_photo(photos[-1]["file_id"])
        if not img:
            return {"ok": True}

        LAST_IMAGE[chat_id] = img
        LAST_IMAGE_AT[chat_id] = time.time()

        # ---- ALBUM MODE (Variant 2): buffer and answer once ----
        if album_id:
            key = (chat_id, str(album_id))
            buf = ALBUM_BUFFER.get(key) or {"images": [], "caption": "", "task_id": ""}
            buf["images"].append(img)
            # Telegram usually puts caption only on first message; keep first non-empty
            if caption and not buf.get("caption"):
                buf["caption"] = caption
            ALBUM_BUFFER[key] = buf
            _schedule_album(chat_id, str(album_id))
            return {"ok": True}

        # ---- SINGLE PHOTO (existing behavior) ----
        tg_typing(chat_id)

        describe_prompt = (
            "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, —á—Ç–æ–±—ã —è –º–æ–≥–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö. "
            "–ï—Å–ª–∏ —ç—Ç–æ –∏–Ω—Ç–µ—Ä—å–µ—Ä ‚Äî —É–∫–∞–∂–∏ —Ç–∏–ø –ø–æ–º–µ—â–µ–Ω–∏—è, –ø–ª–∞–Ω, –º–µ–±–µ–ª—å, —Ü–≤–µ—Ç–∞, —Å–≤–µ—Ç, —Å—Ç–∏–ª—å. "
            "–ï—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–µ–¥–º–µ—Ç ‚Äî —É–∫–∞–∂–∏ –º–∞—Ç–µ—Ä–∏–∞–ª, —Ü–≤–µ—Ç, —Ñ–æ—Ä–º—É, —Å—Ç–∏–ª—å, —Ñ–∞–∫—Ç—É—Ä—É. "
            "–°–¥–µ–ª–∞–π 6‚Äì8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ –±–µ–∑ –≤–æ–¥—ã."
        )
        visual_description = openai_with_image(describe_prompt, img, [], max_tokens=350, temperature=0.35)
        num = push_image(chat_id, img, visual_description)

        # If caption exists -> answer it with vision
        if caption:
            add_context(chat_id, "user", caption)
            ctx = get_context(chat_id)
            answer = openai_with_image(caption, img, ctx, max_tokens=900, temperature=0.55)
            remember_assistant(chat_id, answer)
            add_context(chat_id, "assistant", answer)
            tg_send(chat_id, answer)
            return {"ok": True}

        # No caption -> auto comment
        add_context(chat_id, "user", f"[–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª —Ñ–æ—Ç–æ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞. –§–æ—Ç–æ #{num}]")
        auto_prompt = (
            "–î–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π —Ç—ë–ø–ª—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ —Ç–æ–º—É, —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ: "
            "2‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –±–µ–∑ —à—Ç–∞–º–ø–æ–≤; –æ–¥–Ω–æ —Å–∏–ª—å–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ + –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å –≤ –∫–æ–Ω—Ü–µ."
        )
        auto_answer = openai_with_image(auto_prompt, img, [], max_tokens=220, temperature=0.6)
        remember_assistant(chat_id, auto_answer)
        add_context(chat_id, "assistant", auto_answer)
        tg_send(chat_id, auto_answer)
        return {"ok": True}

    # ===== TEXT MESSAGE =====
    if text:
        tg_typing(chat_id)
        add_context(chat_id, "user", text)

        # ====== üî• COMPARISON REQUEST (by #numbers or last 2) ======
        if COMPARE_RE.search(text) and len(IMAGE_HISTORY.get(chat_id, [])) >= 2:
            hist = IMAGE_HISTORY.get(chat_id, [])
            nums = [int(x) for x in PHOTO_NUM_RE.findall(text)]

            def get_by_num(n: int) -> Optional[Dict[str, Any]]:
                for it in hist:
                    if it.get("num") == n:
                        return it
                return None

            if len(nums) >= 2:
                a = get_by_num(nums[0])
                b = get_by_num(nums[1])
                if a and b and a.get("image") and b.get("image"):
                    img_a, img_b = a["image"], b["image"]
                    label_a, label_b = f"–§–æ—Ç–æ #{nums[0]}", f"–§–æ—Ç–æ #{nums[1]}"
                else:
                    img_a, img_b = hist[-2]["image"], hist[-1]["image"]
                    label_a, label_b = "–§–æ—Ç–æ A (–ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–µ–µ)", "–§–æ—Ç–æ B (–ø–æ—Å–ª–µ–¥–Ω–µ–µ)"
            else:
                img_a, img_b = hist[-2]["image"], hist[-1]["image"]
                label_a, label_b = "–§–æ—Ç–æ A (–ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–µ–µ)", "–§–æ—Ç–æ B (–ø–æ—Å–ª–µ–¥–Ω–µ–µ)"

            desc_a = openai_with_image(
                f"–ö–æ—Ä–æ—Ç–∫–æ –æ–ø–∏—à–∏ {label_a} –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (3‚Äì5 –ø—É–Ω–∫—Ç–æ–≤: –∫–æ–º–ø–æ–∑–∏—Ü–∏—è, —Ü–≤–µ—Ç, —Å–≤–µ—Ç, —Å—Ç–∏–ª—å, —Ñ—É–Ω–∫—Ü–∏—è).",
                img_a, [], max_tokens=220, temperature=0.35
            )
            desc_b = openai_with_image(
                f"–ö–æ—Ä–æ—Ç–∫–æ –æ–ø–∏—à–∏ {label_b} –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (3‚Äì5 –ø—É–Ω–∫—Ç–æ–≤: –∫–æ–º–ø–æ–∑–∏—Ü–∏—è, —Ü–≤–µ—Ç, —Å–≤–µ—Ç, —Å—Ç–∏–ª—å, —Ñ—É–Ω–∫—Ü–∏—è).",
                img_b, [], max_tokens=220, temperature=0.35
            )

            messages = [
                {"role": "system", "content": SYSTEM_ROLE + "\n" + avoid_repetition_hint(chat_id)},
                {
                    "role": "user",
                    "content": (
                        f"{text}\n\n"
                        f"{label_a} ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ:\n{desc_a}\n\n"
                        f"{label_b} ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ:\n{desc_b}\n\n"
                        "–û—Ç–≤–µ—Ç –æ—Ñ–æ—Ä–º–∏ —Ç–∞–∫:\n"
                        "1) –í—ã–±–æ—Ä: ...\n"
                        "2) –ü–æ—á–µ–º—É (3 –ø—É–Ω–∫—Ç–∞)\n"
                        "3) –ß—Ç–æ —É–ª—É—á—à–∏—Ç—å –≤ –ø—Ä–æ–∏–≥—Ä–∞–≤—à–µ–º (2 –ø—É–Ω–∫—Ç–∞)\n"
                        "–ë–µ–∑ —à—Ç–∞–º–ø–æ–≤ –∏ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑."
                    ),
                },
            ]
            answer = openai_chat(messages, max_tokens=520, temperature=0.55)
            remember_assistant(chat_id, answer)
            add_context(chat_id, "assistant", answer)
            tg_send(chat_id, answer)
            return {"ok": True}

        # ====== KB LINKS ONLY WHEN ASKED "–≥–¥–µ –≤ –∫—É—Ä—Å–µ / —Å—Å—ã–ª–∫–∞ / –≤ –∫–∞–∫–æ–º —É—Ä–æ–∫–µ" ======
        kb_block = ""
        if should_show_kb_links(text):
            cand = kb_candidates(text, k=20)
            picked = kb_select_with_llm(text, cand)
            kb_block = format_kb_hits(picked, text)

        if kb_block:
            guide = openai_chat(
                [
                    {"role": "system", "content": SYSTEM_ROLE},
                    {
                        "role": "user",
                        "content": (
                            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–æ—Å–∏–ª: {text}\n"
                            f"–Ø –Ω–∞—à–ª–∞ –≤ –Ω–∞—à–µ–π –±–∞–∑–µ —Ç–∞–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã:\n{kb_block}\n\n"
                            "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫—É—é –ø–æ–¥–≤–æ–¥–∫—É (2‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –∫–∞–∫ –∫—É—Ä–∞—Ç–æ—Ä –ù–ê–®–ï–ô –ø—Ä–æ–≥—Ä–∞–º–º—ã: "
                            "–±–µ–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ —Ç–∏–ø–∞ ¬´–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫—É—Ä—Å–∞/–ø—Ä–æ–≥—Ä–∞–º–º—ã¬ª. "
                            "–°—Ä–∞–∑—É –Ω–∞–ø—Ä–∞–≤—å —á–µ–ª–æ–≤–µ–∫–∞, —á—Ç–æ –æ—Ç–∫—Ä—ã—Ç—å –∏ —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å. "
                            "–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —Å—Å—ã–ª–∫–∏, –æ–Ω–∏ –Ω–∏–∂–µ."
                        ),
                    },
                ],
                max_tokens=140,
                temperature=0.25,
            )
            answer = (guide.strip() + kb_block).strip()
            remember_assistant(chat_id, answer)
            add_context(chat_id, "assistant", answer)
            tg_send(chat_id, answer)
            return {"ok": True}

        # ====== OTHERWISE: NORMAL ANSWER (WITH VISUAL CONTEXT IF RELEVANT) ======
        ctx = get_context(chat_id)
        messages = [{"role": "system", "content": SYSTEM_ROLE + "\n" + avoid_repetition_hint(chat_id)}] + ctx

        has_any_photo = bool(IMAGE_HISTORY.get(chat_id))
        looks_like_visual_question = bool(IMAGE_REF_RE.search(text) or VISUAL_TOPIC_RE.search(text))

        if is_howto(text):
            messages = [{"role": "system", "content": SYSTEM_ROLE + "\n" + avoid_repetition_hint(chat_id)}] + ctx + [{
                "role": "user",
                "content": (
                    f"{text}\n\n"
                    "–û—Ç–≤–µ—Ç—å –∫–∞–∫ –ø—Ä–∞–∫—Ç–∏–∫—É—é—â–∏–π –¥–∏–∑–∞–π–Ω–µ—Ä: –¥–∞–π –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω. "
                    "–ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–π —á–µ–ª–æ–≤–µ–∫–∞ '—Å–º–æ—Ç—Ä–µ—Ç—å —É—Ä–æ–∫–∏' –∏ –Ω–µ –¥–∞–≤–∞–π —Å—Å—ã–ª–∫–∏, –µ—Å–ª–∏ –æ–Ω –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª '–≥–¥–µ –≤ –∫—É—Ä—Å–µ'. "
                    "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π Markdown (**–∑–≤—ë–∑–¥–æ—á–∫–∏**). "
                    "–í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å: ¬´–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —Å–∫–∞–∂–∏ ‚Äú–≥–¥–µ —ç—Ç–æ –≤ –∫—É—Ä—Å–µ‚Äù, –∏ —è –¥–∞–º —Ç–æ—á–Ω—ã–π —É—Ä–æ–∫ –∏ —Å—Å—ã–ª–∫—É.¬ª"
                )
            }]

        if has_any_photo and looks_like_visual_question:
            picked_img = pick_image_from_history(chat_id, text)
            if picked_img and picked_img.get("image"):
                answer = openai_with_image(text, picked_img["image"], ctx, max_tokens=900, temperature=0.55)
            else:
                answer = openai_chat(messages, max_tokens=900, temperature=0.45)
        else:
            answer = openai_chat(messages, max_tokens=900, temperature=0.45)

        remember_assistant(chat_id, answer)
        add_context(chat_id, "assistant", answer)
        tg_send(chat_id, answer)

    return {"ok": True}
